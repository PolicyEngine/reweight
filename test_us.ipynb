{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from policyengine_us import Microsimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "token = os.environ[\"POLICYENGINE_GITHUB_MICRODATA_AUTH_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Microsimulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from policyengine_us.data.datasets.cps.enhanced_cps.loss import generate_model_variables\n",
    "(\n",
    "    household_weights,\n",
    "    weight_adjustment,\n",
    "    values_df,\n",
    "    targets,\n",
    "    targets_array,\n",
    "    equivalisation_factors_array\n",
    ") = generate_model_variables(\"cps_2021\", 2025)\n",
    "\n",
    "#This returns a set of household weights, a random tensor of the same size as the weights tensor,\n",
    "#a Pandas dataframe to transform weights into statistical predictions, a dictionary of target values,\n",
    "#an array of target values, and some equivalisation factors I don't understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weight_adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Then we're working with: this new array * the weights = our estimate.\n",
    "# Then our error in a prediction is based on |predicted - actual|/equivalisation factor. Square that to get\n",
    "# square error, and then average to get MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reweight.logic import reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42868\\710179068.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msim_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mreweight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousehold_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Peter\\Documents\\Summer 2024 Internship\\reweight\\reweight\\logic\\reweight.py\u001b[0m in \u001b[0;36mreweight\u001b[1;34m(initial_weights, estimate_matrix, target_names, target_values, epochs, epoch_step)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# Estimate the targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mtargets_estimate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mestimate_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_estimate\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# Calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Peter\\miniconda3\\envs\\policyengine\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "sim_matrix = torch.tensor(values_df.to_numpy(), dtype=torch.float32)\n",
    "#FIXME: These inputs can't just be NumPy arrays! Also, fix reweight to accommodate stuff.\n",
    "reweight(torch.tensor(household_weights, dtype=torch.float32), sim_matrix, targets, torch.tensor(targets_array, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(household_weights, weight_adjustment, values_df, targets, targets_array, equivalisation_factors_array):\n",
    "    # Initialize a TensorBoard writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    #Create a Torch tensor of log weights\n",
    "    log_weights = torch.log(household_weights)\n",
    "    log_weights.requires_grad_()\n",
    "\n",
    "    sim_matrix = values_df.to_numpy()\n",
    "\n",
    "    # sim_matrix (cross) exp(log_weights) = targets_array\n",
    "    sim_matrix = torch.tensor(sim_matrix, dtype=torch.float32)\n",
    "    #targets_array will be our target values.\n",
    "\n",
    "    optimizer = torch.optim.Adam([log_weights])\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Estimate the targets\n",
    "        targets_estimate = torch.exp(log_weights) @ sim_matrix\n",
    "        # Calculate the loss\n",
    "        loss = torch.mean(((targets_estimate - targets_array)/equivalisation_factors_array) ** 2)\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss for every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "    writer.flush()\n",
    "\n",
    "    final_weights = np.exp(log_weights.detach().numpy())\n",
    "    final_estimates = (\n",
    "        final_weights @ sim_matrix.numpy()\n",
    "    )\n",
    "    true_values = targets\n",
    "    #print(\"Final weights:\", final_weights)\n",
    "    #print(\"Final estimates:\", final_estimates)\n",
    "    #print(\"True values:\", true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2274675965309143\n",
      "Epoch 100, Loss: 0.18678854405879974\n",
      "Epoch 200, Loss: 0.15837892889976501\n",
      "Epoch 300, Loss: 0.13632304966449738\n",
      "Epoch 400, Loss: 0.11881797015666962\n",
      "Epoch 500, Loss: 0.1046074628829956\n",
      "Epoch 600, Loss: 0.09283030778169632\n",
      "Epoch 700, Loss: 0.08289289474487305\n",
      "Epoch 800, Loss: 0.0743781179189682\n",
      "Epoch 900, Loss: 0.06698659062385559\n"
     ]
    }
   ],
   "source": [
    "calibrate(household_weights,\n",
    "    weight_adjustment,\n",
    "    values_df,\n",
    "    targets,\n",
    "    targets_array,\n",
    "    equivalisation_factors_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policyengine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
